{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ai-gvPnADykO",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Module 3: Infer Language Models\n",
    "\n",
    "* DS 6001\n",
    "* Raf Alvarado\n",
    "\n",
    "We now create a series of langage models and evaluate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5x8B8RODykY",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fb3ZsuIsDykn"
   },
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_num', 'para_num', 'sent_num', 'token_num']\n",
    "text_file1 = '../2020-01-23/austen-persuasion.csv'\n",
    "text_file2 = '../2020-01-23/austen-sense.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwrVU8kZDykb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and combine texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = pd.read_csv(text_file1)\n",
    "text2 = pd.read_csv(text_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Kellynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Hall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Somersetshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chap_num  para_num  sent_num  token_num      token_str\n",
       "0         1         1         0          0            Sir\n",
       "1         1         1         0          1         Walter\n",
       "2         1         1         0          2         Elliot\n",
       "3         1         1         0          3             of\n",
       "4         1         1         0          4       Kellynch\n",
       "5         1         1         0          5           Hall\n",
       "6         1         1         0          6             in\n",
       "7         1         1         0          7  Somersetshire\n",
       "8         1         1         0          8            was\n",
       "9         1         1         0          9              a"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1['book_id'] = 1\n",
    "text2['book_id'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th>token_str</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Walter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Elliot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Kellynch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chap_num  para_num  sent_num  token_num token_str  book_id\n",
       "0         1         1         0          0       Sir        1\n",
       "1         1         1         0          1    Walter        1\n",
       "2         1         1         0          2    Elliot        1\n",
       "3         1         1         0          3        of        1\n",
       "4         1         1         0          4  Kellynch        1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.concat([text1, text2]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens.set_index(OHCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kellynch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             token_str\n",
       "book_id chap_num para_num sent_num token_num          \n",
       "1       1        1        0        0               Sir\n",
       "                                   1            Walter\n",
       "                                   2            Elliot\n",
       "                                   3                of\n",
       "                                   4          Kellynch"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens['term_str'] = tokens['token_str'].str.lower().str.replace(r'[\\W_]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_num</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Sir</td>\n",
       "      <td>sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walter</td>\n",
       "      <td>walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elliot</td>\n",
       "      <td>elliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kellynch</td>\n",
       "      <td>kellynch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             token_str  term_str\n",
       "book_id chap_num para_num sent_num token_num                    \n",
       "1       1        1        0        0               Sir       sir\n",
       "                                   1            Walter    walter\n",
       "                                   2            Elliot    elliot\n",
       "                                   3                of        of\n",
       "                                   4          Kellynch  kellynch"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokens['term_str'].value_counts()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'term_str':'n', 'index':'term_str'})\\\n",
    "    .sort_values('term_str')\n",
    "vocab.index.name = 'term_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td></td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>1760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str   n\n",
       "term_id             \n",
       "766               29\n",
       "3456           1   3\n",
       "7639          15   1\n",
       "6602          16   1\n",
       "6938        1760   1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>littlenesses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>improvident</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7261</th>\n",
       "      <td>hotel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>accent</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>linen</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             term_str  n\n",
       "term_id                 \n",
       "6120     littlenesses  1\n",
       "5179      improvident  1\n",
       "7261            hotel  1\n",
       "3474           accent  3\n",
       "3371            linen  3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = vocab.n.sum()\n",
    "vocab['p'] = vocab['n'] / n_tokens\n",
    "vocab['log_p'] = np.log2(vocab['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204833"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "      <th>log_p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>7436</td>\n",
       "      <td>0.036303</td>\n",
       "      <td>-4.783778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>6924</td>\n",
       "      <td>0.033803</td>\n",
       "      <td>-4.886699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>6290</td>\n",
       "      <td>0.030708</td>\n",
       "      <td>-5.025244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>6145</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>-5.058891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>her</td>\n",
       "      <td>3747</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>-5.772568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>3687</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>-5.795857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>3368</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>-5.926412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>was</td>\n",
       "      <td>3198</td>\n",
       "      <td>0.015613</td>\n",
       "      <td>-6.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>-6.033064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.013645</td>\n",
       "      <td>-6.195456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str     n         p     log_p\n",
       "term_id                                   \n",
       "0            the  7436  0.036303 -4.783778\n",
       "1             to  6924  0.033803 -4.886699\n",
       "2            and  6290  0.030708 -5.025244\n",
       "3             of  6145  0.030000 -5.058891\n",
       "4            her  3747  0.018293 -5.772568\n",
       "5              a  3687  0.018000 -5.795857\n",
       "6             in  3368  0.016443 -5.926412\n",
       "7            was  3198  0.015613 -6.001134\n",
       "8              i  3128  0.015271 -6.033064\n",
       "9             it  2795  0.013645 -6.195456"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.sort_values('p', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "text",
    "id": "NfMtOiCYDylX",
    "toc-hr-collapsed": false
   },
   "outputs": [],
   "source": [
    "smooth = vocab['p'].min()\n",
    "def predict_sentence(sent_str):\n",
    "    \n",
    "    # Parse sentence into tokens and normalize string\n",
    "    tokens = pd.DataFrame(sent_str.lower().split(), columns=['term_str'])\n",
    "    \n",
    "    # Link the tokens with model vocabulary\n",
    "    tokens = tokens.merge(vocab, on='term_str', how='left') # Left join is key\n",
    "    \n",
    "    # Add minimum values where token is not in our vocabulary\n",
    "    tokens.loc[tokens['p'].isna(), 'p'] = [smooth]\n",
    "    \n",
    "    # Compute probability of sentence by getting product of token probabilities\n",
    "    p = tokens['p'].product()\n",
    "        \n",
    "    # Print results\n",
    "    print(\"p('{}') = {}\".format(sent_str, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "text",
    "id": "NfMtOiCYDylX",
    "toc-hr-collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p('I love you') = 7.878556023336425e-08\n",
      "p('I love cars') = 4.3312567472987495e-11\n",
      "p('I want to') = 1.8649008463478524e-07\n",
      "p('anne said to') = 2.3099369325723746e-07\n",
      "p('said to her') = 1.7207422835683278e-06\n",
      "p('said to him') = 5.092882819528357e-07\n"
     ]
    }
   ],
   "source": [
    "predict_sentence('I love you')\n",
    "predict_sentence('I love cars')\n",
    "predict_sentence(\"I want to\")\n",
    "predict_sentence(\"anne said to\")\n",
    "predict_sentence(\"said to her\")\n",
    "predict_sentence('said to him')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfMtOiCYDylX",
    "toc-hr-collapsed": true
   },
   "source": [
    "# N-Gram models\n",
    "\n",
    "This function generates models up to the length specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPUTfjSDDylz"
   },
   "outputs": [],
   "source": [
    "def get_ngrams(tokens, n=2):\n",
    "    \n",
    "    global OHCO\n",
    "    \n",
    "    # Create list to store copies of tokens table\n",
    "    X = []\n",
    "    \n",
    "    # Convert the index to cols in order to change the value of token_num\n",
    "    X.append(tokens['term_str'].reset_index())\n",
    "        \n",
    "    # Create copies of token table for each level of ngram, offset by 1, and \n",
    "    # merge with previous \n",
    "    for i in range(1, n):\n",
    "        X.append(X[0].copy())\n",
    "        X[i]['token_num'] = X[i]['token_num'] + i\n",
    "        X[i] = X[i].merge(X[i-1], on=OHCO, how='left', sort=True).fillna('<s>')\n",
    "        \n",
    "    # Compress tables to unique ngrams with counts\n",
    "    for i in range(0, n):\n",
    "        X[i] = X[i].drop(OHCO, 1)\n",
    "        cols = X[i].columns.tolist()\n",
    "        X[i]['n'] = 0\n",
    "        X[i] = X[i].groupby(cols).n.apply(lambda x: x.count()).to_frame()\n",
    "        X[i].index.names = ['w{}'.format(j) for j in range(i+1)]\n",
    "            \n",
    "    # Return just the ngram tables\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "source": [
    "## Generate three models\n",
    "\n",
    "Unigram, bigram, and trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [],
   "source": [
    "m1, m2, m3 = get_ngrams(tokens, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [],
   "source": [
    "# m3.sort_values('n', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute joint probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [],
   "source": [
    "m1['p'] = m1['n'] / m1['n'].sum()\n",
    "m2['p'] = m2['n'] / m2['n'].sum()\n",
    "m3['p'] = m3['n'] / m3['n'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>7436</td>\n",
       "      <td>0.036303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>6924</td>\n",
       "      <td>0.033803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>6290</td>\n",
       "      <td>0.030708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>6145</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>3747</td>\n",
       "      <td>0.018293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n         p\n",
       "w0                 \n",
       "the  7436  0.036303\n",
       "to   6924  0.033803\n",
       "and  6290  0.030708\n",
       "of   6145  0.030000\n",
       "her  3747  0.018293"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.sort_values('p', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_aQs_gk_Dyl7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <td>857</td>\n",
       "      <td>0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <td>814</td>\n",
       "      <td>0.003974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <th>the</th>\n",
       "      <td>683</td>\n",
       "      <td>0.003334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>530</td>\n",
       "      <td>0.002587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <th>was</th>\n",
       "      <td>498</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n         p\n",
       "w0  w1                \n",
       "of  the  857  0.004184\n",
       "to  be   814  0.003974\n",
       "in  the  683  0.003334\n",
       "mrs <s>  530  0.002587\n",
       "it  was  498  0.002431"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.sort_values('p', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>530</td>\n",
       "      <td>0.002587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>369</td>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>244</td>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>227</td>\n",
       "      <td>0.001108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>179</td>\n",
       "      <td>0.000874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>172</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>161</td>\n",
       "      <td>0.000786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>160</td>\n",
       "      <td>0.000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elinor</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>119</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>am</th>\n",
       "      <th>sure</th>\n",
       "      <td>107</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <th>could</th>\n",
       "      <th>not</th>\n",
       "      <td>93</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marianne</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>90</td>\n",
       "      <td>0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>again</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>84</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <th>soon</th>\n",
       "      <th>as</th>\n",
       "      <td>82</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <th>&lt;s&gt;</th>\n",
       "      <td>82</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       n         p\n",
       "w0       w1    w2                 \n",
       "mrs      <s>   <s>   530  0.002587\n",
       "it       <s>   <s>   369  0.001801\n",
       "her      <s>   <s>   244  0.001191\n",
       "him      <s>   <s>   227  0.001108\n",
       "mr       <s>   <s>   179  0.000874\n",
       "you      <s>   <s>   172  0.000840\n",
       "them     <s>   <s>   161  0.000786\n",
       "me       <s>   <s>   160  0.000781\n",
       "elinor   <s>   <s>   119  0.000581\n",
       "i        am    sure  107  0.000522\n",
       "she      could not    93  0.000454\n",
       "marianne <s>   <s>    90  0.000439\n",
       "again    <s>   <s>    84  0.000410\n",
       "as       soon  as     82  0.000400\n",
       "all      <s>   <s>    82  0.000400"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.sort_values('p', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute conditional probabilities\n",
    "\n",
    "$p(w_1|w_0) = p(w_0, w_1) / p(w_0)$\n",
    "\n",
    "$p(w_2|w_0,w_1) = p(w_0, w_1, w_2) / p(w_0, w_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2m = m2.n.unstack().fillna(0).apply(lambda x: x / x.sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3m = m3.n.unstack().fillna(0).apply(lambda x: x / x.sum(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence2(sent_str, n=2):\n",
    "    \n",
    "    # Pick appropriate model\n",
    "    global m1, m2, m3\n",
    "    if n == 1:\n",
    "        M = m1\n",
    "    elif n == 2:\n",
    "        M = m2\n",
    "    elif n == 3:\n",
    "        M = m3\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    # Get smoothing \n",
    "    smooth = M.p.min()\n",
    "    \n",
    "    # Add sentence padding (Hacky)\n",
    "    padded_sent_str = sent_str + (' <s>' * (n-1))\n",
    "    \n",
    "    # Parse sentence into tokens and normalize string\n",
    "    tokens = pd.DataFrame(padded_sent_str.lower().split(), columns=['term_str'])\n",
    "    \n",
    "    # Generate ngram keys \n",
    "    ngrams = []\n",
    "    offset = n - 1\n",
    "    for i in range(offset, tokens.shape[0]):\n",
    "        ngram = []\n",
    "        w = tokens.iloc[i].term_str\n",
    "        for j in range(n):\n",
    "            ngram.append(tokens.iloc[i-j].term_str)\n",
    "        ngram.reverse()\n",
    "        ngrams.append(ngram)\n",
    "        \n",
    "    # Compute the probability of the sentence\n",
    "    L = 0\n",
    "    for ngram in ngrams:\n",
    "        try:\n",
    "            p_ngram = M.loc[tuple(ngram)].p\n",
    "        except KeyError:\n",
    "            p_ngram = smooth\n",
    "        L += np.log2(p_ngram)\n",
    "    P = np.exp(L)\n",
    "    \n",
    "    print(sent_str, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you 5.645972739472476e-11\n",
      "I love cars 1.118907816687782e-15\n",
      "I want to 1.9570792682414204e-10\n",
      "anne said to 2.6650097828995353e-10\n",
      "said to her 4.829429322644128e-09\n",
      "said to him 8.338111808245719e-10\n"
     ]
    }
   ],
   "source": [
    "predict_sentence2('I love you', 1)\n",
    "predict_sentence2('I love cars', 1)\n",
    "predict_sentence2(\"I want to\", 1)\n",
    "predict_sentence2(\"anne said to\", 1)\n",
    "predict_sentence2(\"said to her\", 1)\n",
    "predict_sentence2('said to him', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you 1.6912924832811006e-18\n",
      "I love cars 2.0639180372517065e-22\n",
      "I want to 2.0994247126049545e-19\n",
      "anne said to 7.112019880991409e-20\n",
      "said to her 7.131778675619001e-15\n",
      "said to him 1.2820268067010739e-15\n"
     ]
    }
   ],
   "source": [
    "predict_sentence2('I love you', 2)\n",
    "predict_sentence2('I love cars', 2)\n",
    "predict_sentence2(\"I want to\", 2)\n",
    "predict_sentence2(\"anne said to\", 2)\n",
    "predict_sentence2(\"said to her\", 2)\n",
    "predict_sentence2('said to him', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you 1.725817247418853e-20\n",
      "I love cars 1.0275642842631827e-23\n",
      "I want to 2.0994247126049545e-19\n",
      "anne said to 1.1935219350244338e-21\n",
      "said to her 6.065124721977218e-18\n",
      "said to him 9.465985002423803e-18\n"
     ]
    }
   ],
   "source": [
    "predict_sentence2('I love you', 3)\n",
    "predict_sentence2('I love cars', 3)\n",
    "predict_sentence2(\"I want to\", 2)\n",
    "predict_sentence2(\"anne said to\", 3)\n",
    "predict_sentence2(\"said to her\", 3)\n",
    "predict_sentence2('said to him', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col0 {\n",
       "            background-color:  #53b466;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col1 {\n",
       "            background-color:  #004e1f;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col2 {\n",
       "            background-color:  #98d594;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col3 {\n",
       "            background-color:  #bbe4b4;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col4 {\n",
       "            background-color:  #76c578;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col5 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col6 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col7 {\n",
       "            background-color:  #aedea7;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col0 {\n",
       "            background-color:  #cfecc9;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col1 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col2 {\n",
       "            background-color:  #60ba6c;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col3 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col4 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col5 {\n",
       "            background-color:  #58b668;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col6 {\n",
       "            background-color:  #3fa85b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col7 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col0 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col1 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col2 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col3 {\n",
       "            background-color:  #f4fbf2;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col4 {\n",
       "            background-color:  #f2faef;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col5 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col6 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col7 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col0 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col1 {\n",
       "            background-color:  #91d28e;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col2 {\n",
       "            background-color:  #edf8e9;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col3 {\n",
       "            background-color:  #00481d;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col4 {\n",
       "            background-color:  #95d391;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col5 {\n",
       "            background-color:  #d4eece;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col6 {\n",
       "            background-color:  #e8f6e4;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col7 {\n",
       "            background-color:  #a2d99c;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col0 {\n",
       "            background-color:  #e8f6e4;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col1 {\n",
       "            background-color:  #e7f6e3;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col2 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col3 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col4 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col5 {\n",
       "            background-color:  #70c274;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col6 {\n",
       "            background-color:  #60ba6c;\n",
       "        }    #T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col7 {\n",
       "            background-color:  #bce4b5;\n",
       "        }</style>  \n",
       "<table id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"index_name level0\" >w1</th> \n",
       "        <th class=\"col_heading level0 col0\" >is</th> \n",
       "        <th class=\"col_heading level0 col1\" >had</th> \n",
       "        <th class=\"col_heading level0 col2\" >was</th> \n",
       "        <th class=\"col_heading level0 col3\" >felt</th> \n",
       "        <th class=\"col_heading level0 col4\" >thought</th> \n",
       "        <th class=\"col_heading level0 col5\" >looked</th> \n",
       "        <th class=\"col_heading level0 col6\" >said</th> \n",
       "        <th class=\"col_heading level0 col7\" >saw</th> \n",
       "    </tr>    <tr> \n",
       "        <th class=\"index_name level0\" >w0</th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0level0_row0\" class=\"row_heading level0 row0\" >he</th> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col0\" class=\"data row0 col0\" >0.0578035</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col1\" class=\"data row0 col1\" >0.14499</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col2\" class=\"data row0 col2\" >0.120906</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col3\" class=\"data row0 col3\" >0.00529865</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col4\" class=\"data row0 col4\" >0.00481696</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col5\" class=\"data row0 col5\" >0.00867052</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col6\" class=\"data row0 col6\" >0.0163776</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row0_col7\" class=\"data row0 col7\" >0.00529865</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0level0_row1\" class=\"row_heading level0 row1\" >she</th> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col0\" class=\"data row1 col0\" >0.0242842</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col1\" class=\"data row1 col1\" >0.148967</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col2\" class=\"data row1 col2\" >0.135194</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col3\" class=\"data row1 col3\" >0.0181225</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col4\" class=\"data row1 col4\" >0.00978615</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col5\" class=\"data row1 col5\" >0.0050743</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col6\" class=\"data row1 col6\" >0.0105111</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row1_col7\" class=\"data row1 col7\" >0.0159478</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0level0_row2\" class=\"row_heading level0 row2\" >it</th> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col0\" class=\"data row2 col0\" >0.0969589</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col1\" class=\"data row2 col1\" >0.0225403</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col2\" class=\"data row2 col2\" >0.178175</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col3\" class=\"data row2 col3\" >0.000357782</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col4\" class=\"data row2 col4\" >0.000357782</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col5\" class=\"data row2 col5\" >0.000357782</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col6\" class=\"data row2 col6\" >0.000357782</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row2_col7\" class=\"data row2 col7\" >0</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0level0_row3\" class=\"row_heading level0 row3\" >anne</th> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col0\" class=\"data row3 col0\" >0.00397614</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col1\" class=\"data row3 col1\" >0.0755467</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col2\" class=\"data row3 col2\" >0.0894632</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col3\" class=\"data row3 col3\" >0.0178926</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col4\" class=\"data row3 col4\" >0.00397614</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col5\" class=\"data row3 col5\" >0.00198807</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col6\" class=\"data row3 col6\" >0.00198807</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row3_col7\" class=\"data row3 col7\" >0.00596421</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0level0_row4\" class=\"row_heading level0 row4\" >wentworth</th> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col0\" class=\"data row4 col0\" >0.0137615</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col1\" class=\"data row4 col1\" >0.0366972</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col2\" class=\"data row4 col2\" >0.0825688</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col3\" class=\"data row4 col3\" >0</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col4\" class=\"data row4 col4\" >0</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col5\" class=\"data row4 col5\" >0.00458716</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col6\" class=\"data row4 col6\" >0.00917431</td> \n",
       "        <td id=\"T_02983aca_4390_11ea_80a0_8c859027f1b0row4_col7\" class=\"data row4 col7\" >0.00458716</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b7a131208>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2m.loc[['he','she','it','anne','wentworth'], \n",
    "        ['is','had','was','felt','thought','looked','said','saw']]\\\n",
    "    .style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_2f2b6940_4390_11ea_b35f_8c859027f1b0row0_col0 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }    #T_2f2b6940_4390_11ea_b35f_8c859027f1b0row0_col1 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_2f2b6940_4390_11ea_b35f_8c859027f1b0row1_col0 {\n",
       "            background-color:  #00441b;\n",
       "        }    #T_2f2b6940_4390_11ea_b35f_8c859027f1b0row1_col1 {\n",
       "            background-color:  #f7fcf5;\n",
       "        }</style>  \n",
       "<table id=\"T_2f2b6940_4390_11ea_b35f_8c859027f1b0\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"index_name level0\" >w1</th> \n",
       "        <th class=\"col_heading level0 col0\" >felt</th> \n",
       "        <th class=\"col_heading level0 col1\" >said</th> \n",
       "    </tr>    <tr> \n",
       "        <th class=\"index_name level0\" >w0</th> \n",
       "        <th class=\"blank\" ></th> \n",
       "        <th class=\"blank\" ></th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_2f2b6940_4390_11ea_b35f_8c859027f1b0level0_row0\" class=\"row_heading level0 row0\" >he</th> \n",
       "        <td id=\"T_2f2b6940_4390_11ea_b35f_8c859027f1b0row0_col0\" class=\"data row0 col0\" >0.00529865</td> \n",
       "        <td id=\"T_2f2b6940_4390_11ea_b35f_8c859027f1b0row0_col1\" class=\"data row0 col1\" >0.0163776</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_2f2b6940_4390_11ea_b35f_8c859027f1b0level0_row1\" class=\"row_heading level0 row1\" >she</th> \n",
       "        <td id=\"T_2f2b6940_4390_11ea_b35f_8c859027f1b0row1_col0\" class=\"data row1 col0\" >0.0181225</td> \n",
       "        <td id=\"T_2f2b6940_4390_11ea_b35f_8c859027f1b0row1_col1\" class=\"data row1 col1\" >0.0105111</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a487bdef0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2m.loc[['he','she'],['felt','said']].style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPY7ekfXgbE_"
   },
   "source": [
    "# Generate Text\n",
    "\n",
    "We use back-off to account for missing ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(start_word='she', n=250):\n",
    "    words = [start_word]\n",
    "    for i in range(n):\n",
    "        if len(words) == 1:\n",
    "            w = m2m.loc[start_word]\n",
    "            next_word = m2m.loc[start_word].sample(weights=w).index.values[0]\n",
    "        elif len(words) > 1:\n",
    "            bg = tuple(words[-2:])\n",
    "            try:\n",
    "                w = m3m.loc[bg]\n",
    "                next_word = m3m.loc[bg].sample(weights=w).index.values[0]\n",
    "            except KeyError:\n",
    "                ug = bg[1]\n",
    "                if ug == '<s>':\n",
    "                    next_word = m1.sample(weights=m1.p).index[0]\n",
    "                else:\n",
    "                    w = m2m.loc[ug]\n",
    "                    next_word = m2m.loc[ug].sample(weights=w).index.values[0]\n",
    "        words.append(next_word)\n",
    "    text = ' '.join(words)\n",
    "    text = text.replace(' <s> <s>', '.') + '.'\n",
    "    text = text.upper() # To give that telegraph message look :-)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE DOOR WAS OPENED BEFORE SHE KNEW NOT WHAT THEY COULD BE AUTHORISED BY NOTHING ELSE TO BE UNKIND HOWEVER AND AS FOR LADY RUSSELL WOULD LIKE HIM. AND I AM NOT DECEIVED HER. TIME MAY COME WHEN HARRY WILL REGRET THAT THEY WOULD BURST OUT AND BROKEN UP. FEW MOMENTS REFLECTION HOWEVER PRODUCED A GREAT DEAL OF MOST CHARACTERISTIC PROCEEDING. I HAVE HEARD IT YESTERDAY BY CHANCE THAN ANY OTHER WOMAN I NEVER SHALL. HER SPIRITS TO BE FETTERED TO LUCY SHE IS VERY ASTONISHING. PRESENT INSTANCE THIS LAST WEEK AND RATHER VULGAR. TALKED OF TO EVERYBODY. EXCELLENT YOUNG MAN THOUGH HERE IT PLAINLY APPEARED THAT THOUGH THERE COULD HAVE BEEN NOTHING TO WHAT THE GREATEST SIMPLETON IN THE MIDST OF THE TWO FAIR RIVALS WERE THUS DIVIDED FORMING THREE DISTINCT PARTIES. DONE WHEN THEY ARE ALL GONE TOGETHER BLESSED HER MEMORY. SET HIM DOWN AS SHE REJOICED IN THERE BEING NOTHING TO FORFEIT HER ESTEEM SHE THOUGHT ABOUT ME. HAD BEEN PREVIOUSLY INFORMED. MOTHER TO STAY A MINUTE NOT A MOTHER TO PART WITH HER HANDKERCHIEF. HILLS. MUCH WITH ME. MY BROTHER IS LATELY DEAD MARIANNE FOR SOME WORKING CANDLES. WHEN THEY FIRST CAME TO YOU TO CONJURE OUT THAT I KNOW WHAT TO DO. AND FELL BACK IN HER POWER TO AVOID SUSPECTING BEFORE.\n"
     ]
    }
   ],
   "source": [
    "generate_text('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS5559_LMs.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
